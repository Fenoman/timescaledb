-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
-- Check that the vectorized aggregation works properly in the GroupAggregate
-- mode.
\pset null 造
set max_parallel_workers_per_gather = 0;
create table groupagg(t int, s text, value int);
select create_hypertable('groupagg', 't', chunk_time_interval => 10000);
NOTICE:  adding not-null constraint to column "t"
   create_hypertable   
-----------------------
 (1,public,groupagg,t)
(1 row)

insert into groupagg
select
    xfast * 100 + xslow,
    case when xfast = 13 then null else xfast end,
    xfast * 7 + xslow * 3
from generate_series(10, 99) xfast,
    generate_series(1, 1000) xslow
;
alter table groupagg set (timescaledb.compress, timescaledb.compress_segmentby = '',
    timescaledb.compress_orderby = 's');
select count(compress_chunk(x)) from show_chunks('groupagg') x;
 count 
-------
     2
(1 row)

set enable_hashagg to off;
set timescaledb.debug_require_vector_agg to 'require';
select s, sum(value) from groupagg group by s order by s limit 10;
 s  |   sum   
----+---------
 10 | 1571500
 11 | 1578500
 12 | 1585500
 14 | 1599500
 15 | 1606500
 16 | 1613500
 17 | 1620500
 18 | 1627500
 19 | 1634500
 20 | 1641500
(10 rows)

reset timescaledb.debug_require_vector_agg;
select count(decompress_chunk(x)) from show_chunks('groupagg') x;
 count 
-------
     2
(1 row)

alter table groupagg set (timescaledb.compress, timescaledb.compress_segmentby = '',
    timescaledb.compress_orderby = 's nulls first');
select count(compress_chunk(x)) from show_chunks('groupagg') x;
 count 
-------
     2
(1 row)

set timescaledb.debug_require_vector_agg to 'require';
select s , sum(value) from groupagg group by s  order by s  nulls first limit 10;
 s  |   sum   
----+---------
 造  | 1592500
 10 | 1571500
 11 | 1578500
 12 | 1585500
 14 | 1599500
 15 | 1606500
 16 | 1613500
 17 | 1620500
 18 | 1627500
 19 | 1634500
(10 rows)

reset timescaledb.debug_require_vector_agg;
-- More tests for dictionary encoding.
create table text_table(ts int);
select create_hypertable('text_table', 'ts', chunk_time_interval => 3);
NOTICE:  adding not-null constraint to column "ts"
    create_hypertable    
-------------------------
 (3,public,text_table,t)
(1 row)

alter table text_table set (timescaledb.compress);
WARNING:  there was some uncertainty picking the default segment by for the hypertable: You do not have any indexes on columns that can be used for segment_by and thus we are not using segment_by for compression. Please make sure you are not missing any indexes
NOTICE:  default segment by for hypertable "text_table" is set to ""
NOTICE:  default order by for hypertable "text_table" is set to "ts DESC"
insert into text_table select 0 /*, default */ from generate_series(1, 1000) x;
select count(compress_chunk(x)) from show_chunks('text_table') x;
 count 
-------
     1
(1 row)

alter table text_table add column a text default 'default';
alter table text_table set (timescaledb.compress,
    timescaledb.compress_segmentby = '', timescaledb.compress_orderby = 'a');
insert into text_table select 1, '' from generate_series(1, 1000) x;
insert into text_table select 2, 'same' from generate_series(1, 1000) x;
insert into text_table select 3, 'different' || x from generate_series(1, 1000) x;
insert into text_table select 4, case when x % 2 = 0 then null else 'same-with-nulls' end from generate_series(1, 1000) x;
insert into text_table select 5, case when x % 2 = 0 then null else 'different-with-nulls' || x end from generate_series(1, 1000) x;
select count(compress_chunk(x)) from show_chunks('text_table') x;
 count 
-------
     2
(1 row)

set timescaledb.debug_require_vector_agg to 'require';
select a, count(*) from text_table group by a order by a limit 10;
       a       | count 
---------------+-------
               |  1000
 default       |  1000
 different1    |     1
 different10   |     1
 different100  |     1
 different1000 |     1
 different101  |     1
 different102  |     1
 different103  |     1
 different104  |     1
(10 rows)

select a, count(*) from text_table group by a order by a desc limit 10;
            a            | count 
-------------------------+-------
 造                       |  1000
 same                    |  1000
 different-with-nulls1   |     1
 different-with-nulls101 |     1
 different-with-nulls103 |     1
 different-with-nulls105 |     1
 different-with-nulls107 |     1
 different-with-nulls109 |     1
 different-with-nulls11  |     1
 different-with-nulls111 |     1
(10 rows)

reset timescaledb.debug_require_vector_agg;
-- with NULLS FIRST
select count(decompress_chunk(x)) from show_chunks('text_table') x;
 count 
-------
     2
(1 row)

alter table text_table set (timescaledb.compress,
    timescaledb.compress_segmentby = '', timescaledb.compress_orderby = 'a nulls first');
select count(compress_chunk(x)) from show_chunks('text_table') x;
 count 
-------
     2
(1 row)

set timescaledb.debug_require_vector_agg to 'require';
select a, count(*) from text_table group by a order by a nulls first limit 10;
       a       | count 
---------------+-------
 造             |  1000
               |  1000
 default       |  1000
 different1    |     1
 different10   |     1
 different100  |     1
 different1000 |     1
 different101  |     1
 different102  |     1
 different103  |     1
(10 rows)

reset timescaledb.debug_require_vector_agg;
reset enable_hashagg;
reset timescaledb.debug_require_vector_agg;
reset max_parallel_workers_per_gather;
